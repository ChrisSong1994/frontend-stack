# http协议的队头阻塞问题


### HTTP/1.1 中的队头阻塞

在HTTP/1.1中，队头阻塞（Head-of-Line Blocking, HOLB）主要发生在以下两个方面：

1. **请求-响应顺序性**：HTTP/1.1采用了“请求-响应”模型，在一个持久连接上，客户端必须等待前一个请求的响应到达后才能发送下一个请求。这意味着如果某个请求被延迟了（比如因为网络拥塞或服务器处理时间较长），那么后续的所有请求都会被阻塞，即使这些请求的数据已经准备好并且可以立即传输。

2. **TCP分组丢失**：由于HTTP/1.1通常基于TCP协议进行通信，而TCP保证数据包的有序交付。一旦一个TCP段丢失，接收方将不会向应用层传递任何后续到达的数据，直到丢失的数据包被重传并成功接收。这会导致即使是那些已经到达的数据也无法及时处理，从而造成额外的延迟。

### HTTP/2 如何解决队头阻塞

HTTP/2引入了几项关键技术特性来克服HTTP/1.1中的队头阻塞问题：

1. **多路复用（Multiplexing）**：HTTP/2允许在一个TCP连接上同时发送多个请求和响应。每个请求和响应都被分割成更小的帧，并且这些帧可以交错发送。通过这种方式，即使某些帧丢失了，其他帧仍然可以继续被处理，不会因为一个帧的问题而影响整个连接上的所有通信。

2. **流（Streams）与帧（Frames）**：在HTTP/2中，每个请求/响应被称为一条消息，每条消息又被分解为多个帧。每个帧都包含一个流标识符，用来识别它属于哪个流。这样，即使多个请求共享同一个TCP连接，它们也可以独立地进行传输和处理，避免了由于单个请求导致的整体阻塞。

3. **头部压缩（Header Compression）**：虽然这不是直接解决队头阻塞的方法，但是通过减少每个请求/响应的头部大小，可以提高整体的传输效率，间接帮助减轻潜在的阻塞情况。

尽管HTTP/2解决了HTTP/1.1层面的队头阻塞问题，但由于它依旧依赖于TCP作为传输层协议，因此在TCP层面上的队头阻塞依然存在。也就是说，如果底层TCP发生丢包，仍然需要等待重传，这会影响所有正在使用该TCP连接的流。

为了彻底解决这个问题，后来的HTTP/3协议采用了QUIC作为其传输层协议，这是一种基于UDP的协议，能够提供类似于TCP的可靠性保障但又不受制于TCP的严格顺序要求，从而进一步减少了队头阻塞的影响。